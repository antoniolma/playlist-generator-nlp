{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "120569fd",
   "metadata": {},
   "source": [
    "# Projeto - Natural Language Processing (NLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b704eee6",
   "metadata": {},
   "source": [
    "**Integrantes**:\n",
    "- Antonio Lucas Michelon de Almeida\n",
    "- Pedro Nery Affonso dos Santos\n",
    "- Rafael Gordon Paves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ecf514e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from google import genai\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import numpy as np\n",
    "import torch\n",
    "from models import FormatoResposta\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from agents import PlaylistGenerator, Validator\n",
    "import joblib\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27eafffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Captura pedido de música\n",
    "query = input(\"O que você gostaria de ouvir hoje? \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36823b90",
   "metadata": {},
   "source": [
    "## Playlist gerada a partir de uma única requisição ao Gemini (LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d711d100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nome da Música</th>\n",
       "      <th>Artista</th>\n",
       "      <th>Featuring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Umbrella</td>\n",
       "      <td>Rihanna</td>\n",
       "      <td>Jay-Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crazy in Love</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>Jay-Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Family Affair</td>\n",
       "      <td>Mary J. Blige</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yeah!</td>\n",
       "      <td>Usher</td>\n",
       "      <td>Lil Jon &amp; Ludacris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hot in Herre</td>\n",
       "      <td>Nelly</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gold Digger</td>\n",
       "      <td>Kanye West</td>\n",
       "      <td>Jamie Foxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Empire State of Mind</td>\n",
       "      <td>Jay-Z</td>\n",
       "      <td>Alicia Keys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>In Da Club</td>\n",
       "      <td>50 Cent</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lose Control</td>\n",
       "      <td>Missy Elliott</td>\n",
       "      <td>Ciara &amp; Fatman Scoop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>My Boo</td>\n",
       "      <td>Usher</td>\n",
       "      <td>Alicia Keys</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Nome da Música        Artista             Featuring\n",
       "0              Umbrella        Rihanna                 Jay-Z\n",
       "1         Crazy in Love        Beyoncé                 Jay-Z\n",
       "2         Family Affair  Mary J. Blige                  None\n",
       "3                 Yeah!          Usher    Lil Jon & Ludacris\n",
       "4          Hot in Herre          Nelly                  None\n",
       "5           Gold Digger     Kanye West            Jamie Foxx\n",
       "6  Empire State of Mind          Jay-Z           Alicia Keys\n",
       "7            In Da Club        50 Cent                  None\n",
       "8          Lose Control  Missy Elliott  Ciara & Fatman Scoop\n",
       "9                My Boo          Usher           Alicia Keys"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def monta_playlist(texto):\n",
    "    \"\"\"\n",
    "    Função que realiza uma requisição de montagem de playlist diretamente para o Gemini.\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Você é um especialista em música e construção de playlists. \n",
    "    Você deve analisar o seguinte pedido de playlist e construir uma seleção de músicas que se encaixem no tema solicitado.\n",
    "    Refira-se EXCLUSIVAMENTE ao pedido fornecido para criar a playlist.\n",
    "    A playlist deve ser composta por 10 músicas, com o nome da música, do artista e possível featuring.\n",
    "    A resposta deve ser uma lista em formato JSON, com os seguintes campos:\n",
    "    - nome_musica: Nome da música\n",
    "    - artista: Nome do artista\n",
    "    - featuring: Nome do artista convidado (caso exista)\n",
    "\n",
    "    Pedido do usuário: {texto}\n",
    "    \"\"\"\n",
    "\n",
    "    client = genai.Client(api_key=os.getenv('GEMINI_API_KEY'))\n",
    "    resposta = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        contents=prompt,\n",
    "        config={\n",
    "            \"response_mime_type\": \"application/json\",\n",
    "            'response_schema': list[FormatoResposta],\n",
    "            'temperature': 1.0\n",
    "            # 'max_output_tokens': 500,\n",
    "        }\n",
    "    )\n",
    "    return resposta\n",
    "\n",
    "# Resposta do Gemini\n",
    "resposta = monta_playlist(query)\n",
    "# Converte a resposta em um dicionário\n",
    "resposta_dict = json.loads(resposta.text)\n",
    "# Cria um DataFrame a partir da lista de dicionários\n",
    "df = pd.DataFrame(resposta_dict)\n",
    "# Renomeia as colunas\n",
    "df.rename(columns={'nome_musica': 'Nome da Música', 'artista': 'Artista', 'featuring': 'Featuring'}, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed26072",
   "metadata": {},
   "source": [
    "## Playlist gerada a partir de interações entre agentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146ddba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gerador = PlaylistGenerator()\n",
    "critico = Validator(query)\n",
    "\n",
    "# Envia ao gerador de Playlist o request do usuario\n",
    "playlist = gerador.initialRequest(query).text\n",
    "\n",
    "repeticoes = 5\n",
    "for _ in range(repeticoes):\n",
    "    feedback = critico.refactorRequest(playlist)   \n",
    "    playlist = gerador.refactorPlaylist(feedback).text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf2b4e9",
   "metadata": {},
   "source": [
    "## Playlist gerada a partir de BERT embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376d6949",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 575/575 [51:22<00:00,  5.36s/it]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/songs_filtrado.csv')\n",
    "X = df[\"lyrics\"]\n",
    "y = df['tag']\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Utiliza a GPU para fazer as operações, fazendo muito mais rápido para modelos grandes\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "def get_embeddings(text, model, tokenizer):\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "        outputs = model(**inputs)\n",
    "        cls_embedding = outputs.last_hidden_state[0, 0, :].cpu()\n",
    "\n",
    "        # Para nao gastar tanta memoria\n",
    "        del inputs, outputs\n",
    "    return cls_embedding\n",
    "\n",
    "batch_size = 500\n",
    "for batch_i, inicio in enumerate(tqdm(range(0, len(X), batch_size))):\n",
    "    # Se chegou ao fim, garante nao passar o index\n",
    "    fim = inicio+batch_size if inicio+batch_size < len(X) else len(X)\n",
    "\n",
    "    # Pega pequena amostra, para evitar estourar a memoria RAM (kk)\n",
    "    batch = X.iloc[inicio:fim]\n",
    "\n",
    "    embeddings = []\n",
    "    for i in range(len(batch)):\n",
    "        e = get_embeddings(batch.iloc[i], model, tokenizer)\n",
    "        # print(f\"{batch.iloc[i]} :{e.detach().numpy()}\")\n",
    "        embeddings.append(e.detach().numpy())\n",
    "    \n",
    "    embeddings = np.array(embeddings)\n",
    "\n",
    "    # Salva os embeddings por batch, depois vamos juntar tudo\n",
    "    np.save(f'embeddings/bert_emb_{batch_i}.npy', embeddings) \n",
    "\n",
    "    # Libera variaveis pesadas\n",
    "    del embeddings\n",
    "    # Por usar GPU\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa6429c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings = np.array([])\n",
    "\n",
    "for i in tqdm(range(len(os.listdir(\"./embeddings\")))):\n",
    "    f = f\"./embeddings/bert_emb_{i}.npy\"\n",
    "\n",
    "    if i == 0:\n",
    "        embeddings = np.load(f)\n",
    "        continue\n",
    "\n",
    "    embeddings_load = np.load(f)\n",
    "    embeddings = np.append(embeddings, embeddings_load, axis=0)\n",
    "\n",
    "np.save(f'bert_final.npy', embeddings)\n",
    "\n",
    "del embeddings_load\n",
    "del embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aba3f113",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PEDRO\\OneDrive\\Documentos\\Insper\\2025.1\\NLP\\playlist-generator-nlp\\env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     country       0.59      0.31      0.41      1024\n",
      "        misc       0.83      0.65      0.73      1214\n",
      "         pop       0.63      0.70      0.66     15513\n",
      "         rap       0.87      0.93      0.90     27106\n",
      "          rb       0.49      0.18      0.26      3169\n",
      "        rock       0.63      0.59      0.61      9427\n",
      "\n",
      "    accuracy                           0.75     57453\n",
      "   macro avg       0.68      0.56      0.59     57453\n",
      "weighted avg       0.74      0.75      0.74     57453\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('songs_filtrado.csv')\n",
    "y = df['tag']\n",
    "embeddings = np.load(\"./bert_final.npy\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(embeddings, y, test_size=0.2, random_state=42)\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bert_logistic_model.joblib']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(clf, 'bert_logistic_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bbb8e30",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\nBertModel requires the PyTorch library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\nPlease note that you may need to restart your runtime after installation.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Carregar BERT\u001b[39;00m\n\u001b[32m      7\u001b[39m tokenizer = BertTokenizer.from_pretrained(\u001b[33m'\u001b[39m\u001b[33mbert-base-uncased\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m bert_model = \u001b[43mBertModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33mbert-base-uncased\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m device = torch.device(\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m bert_model.to(device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PEDRO\\OneDrive\\Documentos\\Insper\\2025.1\\NLP\\playlist-generator-nlp\\env\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1885\u001b[39m, in \u001b[36mDummyObject.__getattribute__\u001b[39m\u001b[34m(cls, key)\u001b[39m\n\u001b[32m   1883\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (key.startswith(\u001b[33m\"\u001b[39m\u001b[33m_\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key != \u001b[33m\"\u001b[39m\u001b[33m_from_config\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m key == \u001b[33m\"\u001b[39m\u001b[33mis_dummy\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m key == \u001b[33m\"\u001b[39m\u001b[33mmro\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m key == \u001b[33m\"\u001b[39m\u001b[33mcall\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1884\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__getattribute__\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m1885\u001b[39m \u001b[43mrequires_backends\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_backends\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PEDRO\\OneDrive\\Documentos\\Insper\\2025.1\\NLP\\playlist-generator-nlp\\env\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1871\u001b[39m, in \u001b[36mrequires_backends\u001b[39m\u001b[34m(obj, backends)\u001b[39m\n\u001b[32m   1868\u001b[39m         failed.append(msg.format(name))\n\u001b[32m   1870\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m failed:\n\u001b[32m-> \u001b[39m\u001b[32m1871\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m.join(failed))\n",
      "\u001b[31mImportError\u001b[39m: \nBertModel requires the PyTorch library but it was not found in your environment. Checkout the instructions on the\ninstallation page: https://pytorch.org/get-started/locally/ and follow the ones that match your environment.\nPlease note that you may need to restart your runtime after installation.\n"
     ]
    }
   ],
   "source": [
    "# Carregar modelo e dados\n",
    "clf = joblib.load('bert_logistic_model.joblib')\n",
    "embeddings = np.load('bert_final.npy')\n",
    "metadata = pd.read_csv('songs_filtrado.csv')\n",
    "\n",
    "# Carregar BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "bert_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d1d331",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, model, tokenizer):\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "        outputs = model(**inputs)\n",
    "        cls_embedding = outputs.last_hidden_state[0, 0, :].cpu()\n",
    "        del inputs, outputs\n",
    "    return cls_embedding.numpy()\n",
    "\n",
    "def gerar_playlist_bert(query, top_n=10):\n",
    "    \"\"\"\n",
    "    Gera uma playlist baseada na classificação de estilo usando embeddings BERT\n",
    "    \"\"\"\n",
    "    # Gera embedding da query\n",
    "    embedding_query = get_embedding(query, bert_model, tokenizer).reshape(1, -1)\n",
    "\n",
    "    # Classifica a query em uma das tags\n",
    "    predicted_tag = clf.predict(embedding_query)[0]\n",
    "    print(f\"Tag prevista: {predicted_tag}\")\n",
    "\n",
    "    # Filtra as músicas dessa tag\n",
    "    mask = metadata['tag'] == predicted_tag\n",
    "    subset_embeddings = embeddings[mask.values]\n",
    "    subset_metadata = metadata[mask.values]\n",
    "\n",
    "    # Calcula similaridade (cosine similarity)\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    sims = cosine_similarity(embedding_query, subset_embeddings)[0]\n",
    "\n",
    "    # Seleciona os top N mais similares\n",
    "    indices = sims.argsort()[::-1][:top_n]\n",
    "\n",
    "    playlist = subset_metadata.iloc[indices]\n",
    "    return playlist[['title', 'artist', 'tag']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist = gerar_playlist_bert(query)\n",
    "print(playlist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
